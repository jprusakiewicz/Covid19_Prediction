{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "keras.utils.set_random_seed(1)\n",
    "sys.path.append('src')\n",
    "\n",
    "from data.read_data import read_data\n",
    "\n",
    "def add_target(df, cases_column: str = \"cases\", target_column: str = 'target'):\n",
    "    df[target_column] = df[cases_column].shift(-1)\n",
    "\n",
    "\n",
    "def scale_data(df, columns: List[str]):\n",
    "    # df[columns] = Normalizer().fit_transform(df[columns]) # does not improve at all\n",
    "    # df[columns] = MinMaxScaler().fit_transform(df[columns]) # worse\n",
    "    df[columns] = StandardScaler().fit_transform(df[columns]) # better\n",
    "\n",
    "\n",
    "\n",
    "def split_data(df, targets_column: str):\n",
    "    x = df.drop([targets_column], axis=1)\n",
    "    y = df[targets_column].values\n",
    "    del df\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def add_windows(df: pd.DataFrame):\n",
    "    step_features = []\n",
    "    for step in range(1, N_STEPS):\n",
    "        d = pd.DataFrame()\n",
    "        for column in df:\n",
    "            d[f'{column}-{step}'] = df[column].shift(step)\n",
    "        step_features.append(d)\n",
    "\n",
    "    all = [df, *step_features]\n",
    "    all_values = [df.values for df in all]\n",
    "\n",
    "    _2d = pd.concat(all, axis=1).values  # for dataframe\n",
    "    _3d = np.stack(all_values)\n",
    "\n",
    "    return _2d, _3d\n",
    "\n",
    "\n",
    "def remove_rows_with_nan(matrix, tensor, targets):\n",
    "    assert matrix.shape[0] == tensor.shape[1] == len(targets)\n",
    "    matrix = matrix[N_STEPS - 1:-1]\n",
    "    tensor = tensor[:, N_STEPS - 1:-1, :]\n",
    "    targets = targets[N_STEPS - 1:-1]\n",
    "    return matrix, tensor, targets\n",
    "\n",
    "\n",
    "def add_aggregates_2d(matrix):\n",
    "    cases_columns = [CASES_COLUMN_IDX + (columns_number * step) for step in range(N_STEPS)]\n",
    "\n",
    "    mean_values = np.mean(matrix[:, cases_columns], axis=1)\n",
    "    min_values = np.min(matrix[:, cases_columns], axis=1)\n",
    "    max_values = np.max(matrix[:, cases_columns], axis=1)\n",
    "    median_values = np.median(matrix[:, cases_columns], axis=1)\n",
    "    delta = max_values - min_values\n",
    "\n",
    "    return np.c_[matrix, min_values, max_values, mean_values, median_values, delta]\n",
    "\n",
    "\n",
    "def append_vector_to_tensor(tensor, vector):\n",
    "    vector = np.expand_dims(vector, axis=0)\n",
    "    repeated_vector = np.repeat(vector[:, np.newaxis, :], tensor.shape[0], axis=0)\n",
    "    transposed_tensor = np.transpose(repeated_vector, (0, 2, 1))\n",
    "    new_tensor = np.concatenate((tensor, transposed_tensor), axis=2)\n",
    "    return new_tensor\n",
    "\n",
    "\n",
    "def add_aggregates_3d(tensor):\n",
    "    mean_values = np.mean(tensor[:, :, CASES_COLUMN_IDX], axis=0)\n",
    "    min_values = np.min(tensor[:, :, CASES_COLUMN_IDX], axis=0)\n",
    "    max_values = np.max(tensor[:, :, CASES_COLUMN_IDX], axis=0)\n",
    "    median_values = np.median(tensor[:, :, CASES_COLUMN_IDX], axis=0)\n",
    "    delta = max_values - min_values\n",
    "\n",
    "    tensor = append_vector_to_tensor(tensor, mean_values)\n",
    "    tensor = append_vector_to_tensor(tensor, min_values)\n",
    "    tensor = append_vector_to_tensor(tensor, max_values)\n",
    "    tensor = append_vector_to_tensor(tensor, median_values)\n",
    "    tensor = append_vector_to_tensor(tensor, delta)\n",
    "    return tensor\n",
    "\n",
    "N_STEPS = 27\n",
    "\n",
    "# l = [[1, 0, 0], [2, 0, 0], [3, 0, 0], [4, 0, 0], [5, 0, 0], [6, 0, 0], [7, 0, 0], [8, 0, 0], [9, 0, 0], [10, 0, 0]]\n",
    "# df = pd.DataFrame(l, columns=['cases', 'b', 'c'])\n",
    "# df = df.drop([\"b\", \"c\"], axis=1)\n",
    "\n",
    "df = read_data()\n",
    "df = df[df[\"countryterritoryCode\"] == \"POL\"]\n",
    "df['dateRep'] = pd.to_datetime(df['dateRep'], format=\"%d/%m/%Y\")\n",
    "df = df.sort_values(\"dateRep\")\n",
    "df = df.drop(\n",
    "    [\"countryterritoryCode\", \"continentExp\", \"geoId\", \"countriesAndTerritories\", \"dateRep\", \"day\", \"month\", \"year\",\n",
    "     \"popData2020\", \"deaths\"], axis=1)\n",
    "\n",
    "columns_number = len(df.columns)\n",
    "CASES_COLUMN_IDX = 0\n",
    "\n",
    "add_target(df)\n",
    "scale_data(df, columns=['cases'])\n",
    "x, y = split_data(df, 'target')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=False)\n",
    "del x, y\n",
    "x_train_2d, x_train_3d = add_windows(x_train)\n",
    "x_test_2d, x_test_3d = add_windows(x_test)\n",
    "del x_train\n",
    "x_train_2d, x_train_3d, y_train = remove_rows_with_nan(x_train_2d, x_train_3d, y_train)\n",
    "x_test_2d, x_test_3d, y_test = remove_rows_with_nan(x_test_2d, x_test_3d, y_test)\n",
    "\n",
    "x_train_2d = add_aggregates_2d(x_train_2d)\n",
    "x_test_2d = add_aggregates_2d(x_test_2d)\n",
    "\n",
    "x_train_3d = add_aggregates_3d(x_train_3d)\n",
    "x_test_3d = add_aggregates_3d(x_test_3d)\n",
    "\n",
    "keras_model = keras.Sequential([\n",
    "        keras.layers.Bidirectional(\n",
    "            keras.layers.SimpleRNN(units=64, activation=\"relu\"),\n",
    "        ),\n",
    "        keras.layers.Dense(units=4, activation=\"relu\"),\n",
    "        keras.layers.Dense(units=1)\n",
    "\n",
    "    ])\n",
    "# Print the model summary\n",
    "keras_model.compile(loss=keras.losses.MeanSquaredError(),\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "xtensor_train = tf.convert_to_tensor(np.transpose(x_train_3d, (1, 0, 2)), dtype=tf.float16)\n",
    "xtensor_test = tf.convert_to_tensor(np.transpose(x_test_3d, (1, 0, 2)), dtype=tf.float16)\n",
    "\n",
    "keras_model.fit(xtensor_train, y_train, epochs=50)\n",
    "\n",
    "predicted_keras = keras_model.predict(xtensor_test)\n",
    "\n",
    "rmse_keras = mean_squared_error(predicted_keras, y_test, squared=False)\n",
    "r2_keras = r2_score(predicted_keras, y_test)\n",
    "\n",
    "print(\"nn\", rmse_keras, r2_keras)\n",
    "\n",
    "sk_model = DecisionTreeRegressor()\n",
    "\n",
    "sk_model.fit(x_train_2d, y_train)\n",
    "\n",
    "predicted_sk = sk_model.predict(x_test_2d)\n",
    "rmse_sk = mean_squared_error(predicted_sk, y_test, squared=False)\n",
    "r2_sk = r2_score(predicted_sk, y_test)\n",
    "\n",
    "print(\"sk\", rmse_sk, r2_sk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
